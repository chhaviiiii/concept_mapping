StatementID,StatementText,Cluster
4,4. Efficiency improved for documentation,1
5,5. False confidence,1
6,6. AI could provide alternate perspectives,1
11,"11. Better detection (of moles, cancer lumps)",1
13,13. Too much bureaucracy slowing progress,1
15,15. AI could decrease false positives,1
16,16. Proactive preventative care,1
17,17. Benefits in equitable access,1
18,18. AI could free up time for pt care,1
21,21. Helps with generation of ideas can act as a sounding board,1
23,23. AI allows access vast information very quickly to help diagnosis,1
24,24. Benefits in early distress screening,1
25,25. Establishing proper consent,1
27,27. Benefits with patient access to accurate information,1
30,"30. Savings in time, can integrate different information and improve in treatment especially when there is less number of human specialist",1
35,35. AI could be of concern regarding its ongoing validation,1
41,41. Facilitation of clinical research,1
42,42. Improve access to services,1
44,44. AI could help improve accuracy,1
50,increases digestability/highlighting key points,1
53,53. Pooling large volume of data can improve accuracy of AI system and allow for more timely diagnosis and treatment recommendation,1
55,55. AI hallucinations,1
58,58. Noticing patterns and new things humans haven’t noticed,1
59,59. Prediction/prognosis/treatment recommendations,1
61,61. Concerns with power outages and down time procedures,1
62,62. Increased opportunities for innovation,1
64,64. Personalization of AI support tools for patients,1
69,69. Reduce admin burden,1
70,70. Potential in navigation and directing to self-management resources,1
72,72. Ability to make text/conversation more digestable for patients (less technical),1
76,76. Triage diagnostic results for clinicians,1
79,79. AI could help address the human health resources issue,1
80,80. Faster assessments to inform decision-making,1
84,84. Live translation and/or transcription of conversations,1
87,87. Can existing healthcare servers support the use of AI?,1
88,88. Ensuring interpretability of AI tools,1
89,89. Allow clinicians to focus on tasks requiring their expertise,1
90,"90. Identifying and focusing on high-priority areas, such as prevention",1
97,"97. Potential for widening differential diagnosis, widening perspective of patient",1
98,98. Lists possible outcome and risks for the patient,1
100,100. Automation of routine tasks,1
2,2. Concerns with confidentiality,2
7,7. AI could perpetuate existing biases,2
10,10. Concerns with digital literacy and digital divide barriers,2
12,12. Diversification of AI training data and sources,2
19,19. Developing a rigorous privacy and quality assurance framework,2
20,20. AI could be misused,2
22,22. Benefits with accessibility & communication (translating languages lay terms),2
26,26. Concerns with job security,2
28,28. Concerns about personalizing care,2
29,29. Data governance policies and regulations to enhance data quality and accountability,2
31,31. AI could remove human bias,2
33,"33. AI could lead to excessive human delegation, assuming that that AI will take care of it!",2
34,34. Knowledge repositing for learning and research,2
36,36. AI could be of concern to patient privacy,2
37,37. Consultation recording and transcription,2
38,38. Ensuring cybersecurity of AI tools,2
40,40. Concerns with protection of personal health identifiers,2
43,43. Ensuring accessibility and translation,2
45,45. Embed research / quality improvement into all areas,2
47,47. Concerns with attrition of skills in healthcare providers,2
48,48. Preservation of human touch,2
49,49. Loss of human connection/interactions,2
51,51. Collate large databases,2
52,52. AI could engender issues with trust,2
56,56. Multidisciplinary collaboration and training in developing AI models,2
57,"57. 24/7 availability, AI doesn’t get tired or brain fog",2
63,63. Distress is nuanced and often detected in the unsaid of human communication and in a trusting therapeutic relationship,2
65,65. Concerns with difficulty to know older data for training and missing new breakthrough information,2
66,66. Concerns with consent of patient,2
67,67. Racism bias through research (history of medical research),2
68,68. Phased roll-out,2
71,71. Over reliance by physicians and reduced problem solving skills,2
74,"74. Concerns with maintaining up to date information, sources and programming",2
75,75. Data privacy concerns,2
77,77. Concerns with going too far and can’t come back,2
82,82. AI could make mistakes,2
83,"83. Concerns with stability of the system (during virus attack, power outage, system interruption)",2
92,92. Maintaining competency with changing best practices and approuved standards,2
93,93. Minority groups being marginalized,2
95,95. Data ownership and standards and guidelines on AI developed are not established,2
96,96. Possibility of data breaches / data leaks,2
99,99. Cybersecurity concerns,2
1,1. Human oversight during implementation in early days,3
3,3. Concerns with patient acceptability,3
8,8. Minimizing bias and increasing performance and accuracy,3
9,9. Ensuring accountability and oversight of AI,3
14,14. Concerns with liability,3
32,32. Regulation framework and a good understanding of the medico-legal implications,3
39,39. Educating end-users about properly navigating AI,3
46,"data that the AI model is trained on must be good, clean, large and diverse",3
54,54. Concerns with responsibility accountability of AI recommendations,3
60,"60. Concerns with standards for quality, accuracy, etc.",3
73,73. Ensuring clinical validation of AI tools,3
78,78. Control of data by corporations,3
81,81. Concerns with transparency,3
85,85. Establishing guidelines for “best practices” for training AI + clinical validation,3
86,86. Lack of training/knowledge for those using the AI tool in the real world,3
91,91. Concerns that data is held by private companies,3
94,94. Patient/parent/caregiver/provider acceptability,3
