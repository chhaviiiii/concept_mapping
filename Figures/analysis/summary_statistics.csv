StatementID,StatementText,Cluster,Importance,Feasibility
1,1. Human oversight during implementation in early days,4,4.142857142857143,3.857142857142857
2,2. Concerns with confidentiality,1,3.5714285714285716,3.857142857142857
3,3. Concerns with patient acceptability,4,4.142857142857143,3.857142857142857
4,4. Efficiency improved for documentation,3,3.5714285714285716,4.571428571428571
5,5. False confidence,3,3.142857142857143,3.1666666666666665
6,6. AI could provide alternate perspectives,3,3.142857142857143,3.428571428571429
7,7. AI could perpetuate existing biases,2,3.4285714285714284,3.7142857142857144
8,8. Minimizing bias and increasing performance and accuracy,4,4,3.857142857142857
9,9. Ensuring accountability and oversight of AI,4,4,4
10,10. Concerns with digital literacy and digital divide barriers,1,2.7142857142857144,3.142857142857143
11,"11. Better detection (of moles, cancer lumps)",3,3.7142857142857144,4.285714285714286
12,12. Diversification of AI training data and sources,2,3.142857142857143,3.7142857142857144
13,13. Too much bureaucracy slowing progress,3,3.142857142857143,3.2857142857142856
14,14. Concerns with liability,4,3.4285714285714284,3.142857142857143
15,15. AI could decrease false positives,3,3.5714285714285716,4
16,16. Proactive preventative care,3,3.2857142857142856,3.5714285714285716
17,17. Benefits in equitable access,2,3.142857142857143,3.5714285714285716
18,18. AI could free up time for pt care,3,3.857142857142857,4.285714285714286
19,19. Developing a rigorous privacy and quality assurance framework,1,3.4285714285714284,4
20,20. AI could be misused,1,2.857142857142857,3
21,21. Helps with generation of ideas can act as a sounding board,3,3,4.428571428571429
22,22. Benefits with accessibility & communication (translating languages lay terms),2,3.4285714285714284,4.428571428571429
23,23. AI allows access vast information very quickly to help diagnosis,3,4,4.571428571428571
24,24. Benefits in early distress screening,3,3.5714285714285716,4
25,25. Establishing proper consent,2,2.857142857142857,3.5714285714285716
26,26. Concerns with job security,2,2.142857142857143,2.5714285714285716
27,27. Benefits with patient access to accurate information,3,3.2857142857142856,4.142857142857143
28,28. Concerns about personalizing care,2,3,3.7142857142857144
29,29. Data governance policies and regulations to enhance data quality and accountability,1,2.7142857142857144,2.857142857142857
30,"30. Savings in time, can integrate different information and improve in treatment especially when there is less number of human specialist",3,4.142857142857143,4.285714285714286
31,31. AI could remove human bias,1,3.2857142857142856,3.142857142857143
32,32. Regulation framework and a good understanding of the medico-legal implications,4,2.857142857142857,2.7142857142857144
33,"33. AI could lead to excessive human delegation, assuming that that AI will take care of it!",1,3,3.142857142857143
34,34. Knowledge repositing for learning and research,2,2.857142857142857,4.142857142857143
35,35. AI could be of concern regarding its ongoing validation,3,3,3.5714285714285716
36,36. AI could be of concern to patient privacy,1,3,3.142857142857143
37,37. Consultation recording and transcription,2,3.142857142857143,4.666666666666667
38,38. Ensuring cybersecurity of AI tools,1,3.7142857142857144,3.7142857142857144
39,39. Educating end-users about properly navigating AI,4,4,4.142857142857143
40,40. Concerns with protection of personal health identifiers,1,3.428571428571429,3.5714285714285716
41,41. Facilitation of clinical research,3,3.2857142857142856,4.142857142857143
42,42. Improve access to services,3,3.7142857142857144,4.142857142857143
43,43. Ensuring accessibility and translation,1,3.2857142857142856,4
44,44. AI could help improve accuracy,3,3.5714285714285716,4.142857142857143
45,45. Embed research / quality improvement into all areas,2,2.5714285714285716,3.5714285714285716
46,"data that the AI model is trained on must be good, clean, large and diverse",4,3.2857142857142856,2.5714285714285716
47,47. Concerns with attrition of skills in healthcare providers,1,2.857142857142857,3.142857142857143
48,48. Preservation of human touch,2,3.2857142857142856,3.4285714285714284
49,49. Loss of human connection/interactions,1,3.7142857142857144,3.2857142857142856
50,increases digestability/highlighting key points,2,4,4.857142857142857
51,51. Collate large databases,2,3.142857142857143,4.428571428571429
52,52. AI could engender issues with trust,1,2.857142857142857,3.142857142857143
53,53. Pooling large volume of data can improve accuracy of AI system and allow for more timely diagnosis and treatment recommendation,3,3.5714285714285716,3.857142857142857
54,54. Concerns with responsibility accountability of AI recommendations,4,3.4285714285714284,3.2857142857142856
55,55. AI hallucinations,3,3.142857142857143,3.4285714285714284
56,56. Multidisciplinary collaboration and training in developing AI models,1,3,3.7142857142857144
57,"57. 24/7 availability, AI doesn’t get tired or brain fog",2,3.2857142857142856,4.714285714285714
58,58. Noticing patterns and new things humans haven’t noticed,3,3.5714285714285716,4.428571428571429
59,59. Prediction/prognosis/treatment recommendations,3,4,4.428571428571429
60,"60. Concerns with standards for quality, accuracy, etc.",4,3,3.2857142857142856
61,61. Concerns with power outages and down time procedures,2,2,3.142857142857143
62,62. Increased opportunities for innovation,2,2.857142857142857,4
63,63. Distress is nuanced and often detected in the unsaid of human communication and in a trusting therapeutic relationship,1,3.4285714285714284,2.857142857142857
64,64. Personalization of AI support tools for patients,3,3.7142857142857144,3.7142857142857144
65,65. Concerns with difficulty to know older data for training and missing new breakthrough information,2,2.7142857142857144,3.857142857142857
66,66. Concerns with consent of patient,1,3.4285714285714284,3.4285714285714284
67,67. Racism bias through research (history of medical research),1,3,2.7142857142857144
68,68. Phased roll-out,2,3.142857142857143,4.571428571428571
69,69. Reduce admin burden,3,4,4.571428571428571
70,70. Potential in navigation and directing to self-management resources,3,3.7142857142857144,4.285714285714286
71,71. Over reliance by physicians and reduced problem solving skills,1,2.857142857142857,3.2857142857142856
72,72. Ability to make text/conversation more digestable for patients (less technical),3,3.4285714285714284,4.285714285714286
73,73. Ensuring clinical validation of AI tools,4,3.5714285714285716,3.857142857142857
74,"74. Concerns with maintaining up to date information, sources and programming",2,2.857142857142857,3.7142857142857144
75,75. Data privacy concerns,1,3.428571428571429,3
76,76. Triage diagnostic results for clinicians,3,3.5714285714285716,4.285714285714286
77,77. Concerns with going too far and can’t come back,2,2.4285714285714284,2.7142857142857144
78,78. Control of data by corporations,4,3.142857142857143,2.857142857142857
79,79. AI could help address the human health resources issue,3,3.7142857142857144,3.7142857142857144
80,80. Faster assessments to inform decision-making,3,3.5714285714285716,4.142857142857143
81,81. Concerns with transparency,4,3.5714285714285716,3.2857142857142856
82,82. AI could make mistakes,1,3.2857142857142856,3.2857142857142856
83,"83. Concerns with stability of the system (during virus attack, power outage, system interruption)",1,2.7142857142857144,2.7142857142857144
84,84. Live translation and/or transcription of conversations,2,3.857142857142857,4.571428571428571
85,85. Establishing guidelines for “best practices” for training AI + clinical validation,4,3.7142857142857144,3.5714285714285716
86,86. Lack of training/knowledge for those using the AI tool in the real world,4,3.142857142857143,3.857142857142857
87,87. Can existing healthcare servers support the use of AI?,2,1.7142857142857142,3.7142857142857144
88,88. Ensuring interpretability of AI tools,3,3.142857142857143,4
89,89. Allow clinicians to focus on tasks requiring their expertise,3,4.428571428571429,4.428571428571429
90,"90. Identifying and focusing on high-priority areas, such as prevention",3,3.2857142857142856,4.142857142857143
91,91. Concerns that data is held by private companies,4,3.4285714285714284,2.7142857142857144
92,92. Maintaining competency with changing best practices and approuved standards,2,3.142857142857143,3.4285714285714284
93,93. Minority groups being marginalized,2,3.142857142857143,3.2857142857142856
94,94. Patient/parent/caregiver/provider acceptability,4,4,3.4285714285714284
95,95. Data ownership and standards and guidelines on AI developed are not established,1,2.857142857142857,3.5714285714285716
96,96. Possibility of data breaches / data leaks,1,3.142857142857143,3
97,"97. Potential for widening differential diagnosis, widening perspective of patient",3,2.857142857142857,4.142857142857143
98,98. Lists possible outcome and risks for the patient,3,4,4.285714285714286
99,99. Cybersecurity concerns,1,3.142857142857143,3
100,100. Automation of routine tasks,3,4.142857142857143,4.714285714285714
